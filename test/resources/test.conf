odinson {

  displayField = raw

  compiler {

    # fields available per token
    allTokenFields = [
      ${odinson.index.rawTokenField},
      ${odinson.index.wordTokenField},
      ${odinson.index.normalizedTokenField},
      ${odinson.index.lemmaTokenField},
      ${odinson.index.posTagTokenField},
      ${odinson.index.chunkTokenField},
      ${odinson.index.entityTokenField},
      ${odinson.index.incomingTokenField},
      ${odinson.index.outgoingTokenField},
    ]

    # the token field to be used when none is specified
    defaultTokenField = ${odinson.index.normalizedTokenField}

    dependenciesField = ${odinson.index.dependenciesField}

    incomingTokenField = ${odinson.index.incomingTokenField}

    outgoingTokenField = ${odinson.index.outgoingTokenField}

    # if we are using the normalizedTokenField as the default
    # then we should casefold the queries to the default field
    # so that they match
    aggressiveNormalizationToDefaultField = true
  }

  index {
    incremental = true
    refreshMs = -1
    # NOTE: parentDocFieldFileName must be included
    # **and stored** in order to retrieve sentence/doc/metadata JSON
    parentDocFieldFileName = fileName

    storedFields = [
      ${odinson.displayField},
      ${odinson.index.parentDocFieldFileName}
    ]

        # the raw token
    rawTokenField = raw

    # the word itself
    wordTokenField = word

    # a normalized version of the token
    normalizedTokenField = norm

    # the normalized field will include values from the following fields
    addToNormalizedField = [
      ${odinson.index.rawTokenField},
      ${odinson.index.wordTokenField},
    ]

    # token attribute fields
    lemmaTokenField = "lemma"

    posTagTokenField = "tag"

    chunkTokenField = "chunk"

    entityTokenField = "entity"

    incomingTokenField = "incoming"

    outgoingTokenField = "outgoing"

    dependenciesField = "dependencies"

    maxNumberOfTokensPerSentence = 100

    # Sometimes there are tokens in documents which are incompatible with the way we use Lucene.
    # In those cases, we replace the token with this character (default: ï¿½).
    invalidCharacterReplacement = "\ufffd"
  }

}
